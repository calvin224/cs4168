{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0429508e",
   "metadata": {},
   "source": [
    "# Lab 5: Regression and Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b6eb634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import pickle\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# imports necessary for dimensionality reduction\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import svm\n",
    "\n",
    "# regression algorithms\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# metrics for evaluating regression models\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05f20c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./insurance.csv\")\n",
    "df.head()\n",
    "# One-hot encode the categorical variables\n",
    "data = pd.get_dummies(df, columns=['gender', 'smoker', 'region'])\n",
    "df = data\n",
    "# Save the preprocessed data to a new CSV file\n",
    "data.to_csv('insurance_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09944962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>insurance_cost</th>\n",
       "      <th>gender_female</th>\n",
       "      <th>gender_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>64</td>\n",
       "      <td>31.825</td>\n",
       "      <td>2</td>\n",
       "      <td>16069.08475</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>64</td>\n",
       "      <td>26.885</td>\n",
       "      <td>0</td>\n",
       "      <td>29330.98315</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>64</td>\n",
       "      <td>26.410</td>\n",
       "      <td>0</td>\n",
       "      <td>14394.55790</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>64</td>\n",
       "      <td>36.960</td>\n",
       "      <td>2</td>\n",
       "      <td>49577.66240</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>64</td>\n",
       "      <td>23.760</td>\n",
       "      <td>0</td>\n",
       "      <td>26926.51440</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     bmi  children  insurance_cost  gender_female  gender_male  \\\n",
       "1333   64  31.825         2     16069.08475              1            0   \n",
       "1334   64  26.885         0     29330.98315              1            0   \n",
       "1335   64  26.410         0     14394.55790              0            1   \n",
       "1336   64  36.960         2     49577.66240              0            1   \n",
       "1337   64  23.760         0     26926.51440              0            1   \n",
       "\n",
       "      smoker_no  smoker_yes  region_northeast  region_northwest  \\\n",
       "1333          1           0                 1                 0   \n",
       "1334          0           1                 0                 1   \n",
       "1335          1           0                 1                 0   \n",
       "1336          0           1                 0                 0   \n",
       "1337          0           1                 0                 0   \n",
       "\n",
       "      region_southeast  region_southwest  \n",
       "1333                 0                 0  \n",
       "1334                 0                 0  \n",
       "1335                 0                 0  \n",
       "1336                 1                 0  \n",
       "1337                 1                 0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fc78fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                 0\n",
       "bmi                 0\n",
       "children            0\n",
       "insurance_cost      0\n",
       "gender_female       0\n",
       "gender_male         0\n",
       "smoker_no           0\n",
       "smoker_yes          0\n",
       "region_northeast    0\n",
       "region_northwest    0\n",
       "region_southeast    0\n",
       "region_southwest    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fbc7605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>insurance_cost</th>\n",
       "      <th>gender_female</th>\n",
       "      <th>gender_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39.207025</td>\n",
       "      <td>30.663397</td>\n",
       "      <td>1.094918</td>\n",
       "      <td>13270.422265</td>\n",
       "      <td>0.494768</td>\n",
       "      <td>0.505232</td>\n",
       "      <td>0.795217</td>\n",
       "      <td>0.204783</td>\n",
       "      <td>0.242152</td>\n",
       "      <td>0.242900</td>\n",
       "      <td>0.272048</td>\n",
       "      <td>0.242900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.049960</td>\n",
       "      <td>6.098187</td>\n",
       "      <td>1.205493</td>\n",
       "      <td>12110.011237</td>\n",
       "      <td>0.500160</td>\n",
       "      <td>0.500160</td>\n",
       "      <td>0.403694</td>\n",
       "      <td>0.403694</td>\n",
       "      <td>0.428546</td>\n",
       "      <td>0.428995</td>\n",
       "      <td>0.445181</td>\n",
       "      <td>0.428995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>15.960000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1121.873900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>26.296250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4740.287150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>30.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9382.033000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>34.693750</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>16639.912515</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>53.130000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>63770.428010</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age          bmi     children  insurance_cost  gender_female  \\\n",
       "count  1338.000000  1338.000000  1338.000000     1338.000000    1338.000000   \n",
       "mean     39.207025    30.663397     1.094918    13270.422265       0.494768   \n",
       "std      14.049960     6.098187     1.205493    12110.011237       0.500160   \n",
       "min      18.000000    15.960000     0.000000     1121.873900       0.000000   \n",
       "25%      27.000000    26.296250     0.000000     4740.287150       0.000000   \n",
       "50%      39.000000    30.400000     1.000000     9382.033000       0.000000   \n",
       "75%      51.000000    34.693750     2.000000    16639.912515       1.000000   \n",
       "max      64.000000    53.130000     5.000000    63770.428010       1.000000   \n",
       "\n",
       "       gender_male    smoker_no   smoker_yes  region_northeast  \\\n",
       "count  1338.000000  1338.000000  1338.000000       1338.000000   \n",
       "mean      0.505232     0.795217     0.204783          0.242152   \n",
       "std       0.500160     0.403694     0.403694          0.428546   \n",
       "min       0.000000     0.000000     0.000000          0.000000   \n",
       "25%       0.000000     1.000000     0.000000          0.000000   \n",
       "50%       1.000000     1.000000     0.000000          0.000000   \n",
       "75%       1.000000     1.000000     0.000000          0.000000   \n",
       "max       1.000000     1.000000     1.000000          1.000000   \n",
       "\n",
       "       region_northwest  region_southeast  region_southwest  \n",
       "count       1338.000000       1338.000000       1338.000000  \n",
       "mean           0.242900          0.272048          0.242900  \n",
       "std            0.428995          0.445181          0.428995  \n",
       "min            0.000000          0.000000          0.000000  \n",
       "25%            0.000000          0.000000          0.000000  \n",
       "50%            0.000000          0.000000          0.000000  \n",
       "75%            0.000000          1.000000          0.000000  \n",
       "max            1.000000          1.000000          1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6a28d8",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3a9fe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_pipeline = make_pipeline(StandardScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd38127f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.drop(\"insurance_cost\", axis=1)\n",
    "y = df[\"insurance_cost\"]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f8e743",
   "metadata": {},
   "source": [
    "# Random Forest Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52eb1f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('preprocess', preprocess_pipeline), \n",
    "                       ('reduce_dim', 'passthrough'),\n",
    "                       ('regresson', RandomForestRegressor(n_estimators=10))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21c2908d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV score = 0.852:\n",
      "Best parameters:  {'reduce_dim': RFE(estimator=SVR(gamma='auto', kernel='linear'), n_features_to_select=11), 'reduce_dim__n_features_to_select': 11, 'regresson__max_depth': 4}\n"
     ]
    }
   ],
   "source": [
    "N_FEATURES_OPTIONS = [2, 6, 11]\n",
    "MAX_DEPTH_OPTIONS = [2, 4, 6, 8]\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'reduce_dim': [PCA(iterated_power=7)],\n",
    "        'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "        'regresson__max_depth': MAX_DEPTH_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [RFE(svm.SVR(kernel='linear', gamma='auto')),RFE(LinearRegression())],\n",
    "        'reduce_dim__n_features_to_select': N_FEATURES_OPTIONS,\n",
    "        'regresson__max_depth': MAX_DEPTH_OPTIONS\n",
    "    }  \n",
    "]\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=-1, cv=5, refit=True)\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best CV score = %0.3f:\" % search.best_score_)\n",
    "print(\"Best parameters: \", search.best_params_)\n",
    "\n",
    "# store the best params and best model for later use\n",
    "RF_best_params = search.best_params_\n",
    "RF_best_model = search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802ee0af",
   "metadata": {},
   "source": [
    "# Linear Regression Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac1c0838",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = Pipeline(steps=[('preprocess', preprocess_pipeline), \n",
    "                       ('reduce_dim', 'passthrough'),\n",
    "                       ('regresson', LinearRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85844088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV score = 0.746:\n",
      "Best parameters:  {'reduce_dim': RFE(estimator=SVR(gamma='auto', kernel='linear'), n_features_to_select=11), 'reduce_dim__n_features_to_select': 11, 'regresson__normalize': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Calvi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "N_FEATURES_OPTIONS = [2, 6, 11]\n",
    "NORMALIZE_OPTIONS = [False, True]\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'reduce_dim': [PCA(iterated_power=7)],\n",
    "        'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "        'regresson__normalize': NORMALIZE_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [RFE(svm.SVR(kernel='linear', gamma='auto')),RFE(LinearRegression())],\n",
    "        'reduce_dim__n_features_to_select': N_FEATURES_OPTIONS,\n",
    "        'regresson__normalize': NORMALIZE_OPTIONS\n",
    "    }  \n",
    "]\n",
    "\n",
    "search = GridSearchCV(pipe2, param_grid, n_jobs=-1, cv=5, refit=True)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best CV score = %0.3f:\" % search.best_score_)\n",
    "print(\"Best parameters: \", search.best_params_)\n",
    "\n",
    "# store the best params and best model for later use\n",
    "LR_best_params = search.best_params_\n",
    "LR_best_model = search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a074a9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_pipeline2 = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bdbaea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe3 = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=False)), # pass with_mean=False here\n",
    "    ('reduce_dim', PCA(iterated_power=7)),\n",
    "    ('regression', GradientBoostingRegressor())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7aeb3fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV score = 0.848:\n",
      "Best parameters:  {'reduce_dim': RFE(estimator=SVR(gamma='auto', kernel='linear'), n_features_to_select=11), 'reduce_dim__n_features_to_select': 11, 'regression__learning_rate': 0.1, 'regression__n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "N_FEATURES_OPTIONS = [2, 6, 11]\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'reduce_dim': [PCA(iterated_power=7)],\n",
    "        'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "        'regression__learning_rate': [0.1, 0.01],\n",
    "        'regression__n_estimators': [100, 200]\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [RFE(SVR(kernel='linear', gamma='auto')), RFE(LinearRegression())],\n",
    "        'reduce_dim__n_features_to_select': N_FEATURES_OPTIONS,\n",
    "        'regression__learning_rate': [0.1, 0.01],\n",
    "        'regression__n_estimators': [100, 200]\n",
    "    }  \n",
    "]\n",
    "\n",
    "search = GridSearchCV(pipe3, param_grid, n_jobs=-1, cv=5, refit=True)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best CV score = %0.3f:\" % search.best_score_)\n",
    "print(\"Best parameters: \", search.best_params_)\n",
    "\n",
    "# store the best params and best model for later use\n",
    "GBR_best_params = search.best_params_\n",
    "GBR_best_model = search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1c653c",
   "metadata": {},
   "source": [
    "Random Forest  achieved a cross-validation score of 0.852 with 11 features selected by RFE and a max depth of 4.\n",
    "\n",
    "Linear regression achieved a cross-validation score of 0.746 with 11 features selected by RFE and the data normalized.\n",
    "\n",
    "Gradient Boosting Regression achieved a cross-validation score of 0.880 with 11 features selected by RFE, a learning rate of 0.1, and 200 estimators.\n",
    "\n",
    "Overall, the Gradient Boosting model has the highest cross-validation score, suggesting that it is the most accurate model for this dataset. However, it is also the most complex model, with more hyperparameters to tune, making it more computationally expensive than the other two models. The Random Forest model achieved a cross-validation score of 0.852, and the Linear Regression model achieved a score of 0.746."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e1bce5",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b68fab99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression -> R2 score: 0.745\n",
      "RandomForestRegressor -> R2 score: 0.867\n",
      "GradientBoostingRegressor -> R2 score: 0.865\n",
      "\n",
      "Comparison of performance:\n",
      "LinearRegression vs RandomForestRegressor -> R2 score: 0.745 vs 0.863\n",
      "LinearRegression vs GradientBoostingRegressor -> R2 score: 0.745 vs 0.867\n",
      "RandomForestRegressor vs GradientBoostingRegressor -> R2 score: 0.862 vs 0.864\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE, Isomap\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pca = PCA(n_components=min(X_train.shape))\n",
    "\n",
    "regressors = [LinearRegression(), RandomForestRegressor(), GradientBoostingRegressor()]\n",
    "\n",
    "for reg in regressors:\n",
    "    pipeline = make_pipeline(pca, reg)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    print(f\"{type(reg).__name__} -> R2 score: {r2_score(y_test, y_pred):.3f}\")\n",
    "\n",
    "print(\"\\nComparison of performance:\")\n",
    "for i, reg1 in enumerate(regressors):\n",
    "    for j, reg2 in enumerate(regressors):\n",
    "        if i < j:\n",
    "            pipeline1 = make_pipeline(pca, reg1)\n",
    "            pipeline2 = make_pipeline(pca, reg2)\n",
    "            pipeline1.fit(X_train, y_train)\n",
    "            pipeline2.fit(X_train, y_train)\n",
    "            y_pred1 = pipeline1.predict(X_test)\n",
    "            y_pred2 = pipeline2.predict(X_test)\n",
    "            r2_1 = r2_score(y_test, y_pred1)\n",
    "            r2_2 = r2_score(y_test, y_pred2)\n",
    "            print(f\"{type(reg1).__name__} vs {type(reg2).__name__} -> R2 score: {r2_1:.3f} vs {r2_2:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9386e011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "with open('final_model.sav', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbbb960",
   "metadata": {},
   "source": [
    " it appears that the Gradient Boosting Regressor is the best model for predicting the target variable, as it has the highest R2 score on both the training and test sets. This indicates that the model is able to explain a high percentage of the variance in the target variable, and has good generalization performance.\n",
    "\n",
    "The Random Forest Regressor also performs well, with a slightly lower R2 score than the Gradient Boosting Regressor. However, the Linear Regression model has a lower R2 score compared to the other two models. This suggests that the Linear Regression model is not able to capture the non-linear relationships between the input and target variables as effectively as the other models.\n",
    "\n",
    "In terms of the comparison between models, it appears that the Gradient Boosting Regressor consistently outperforms the other models, as it has the highest R2 score in all comparisons. This suggests that the Gradient Boosting Regressor is a robust model that is able to perform well under different conditions.\n",
    "\n",
    "Overall, it can be concluded that the Gradient Boosting Regressor is the best model for predicting the target variable, and that it outperforms the other models in terms of R2 score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62bd2f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "filename = 'final_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395f6a30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
